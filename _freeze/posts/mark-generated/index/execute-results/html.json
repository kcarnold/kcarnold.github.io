{
  "hash": "910c8642927e80c7c5c5a4ce744178d3",
  "result": {
    "markdown": "---\ntitle: \"Transparency for Generated Text\"\ndate: \"2023-02-17\"\ncategories: [\"ml\", \"llm\", \"nlp\"]\n---\n\nHow should we indicate that some text has been automatically generated? \n\nA few dimensions in the design space:\n\n1. How visible?\n    - do you need to copy the text into a different tool to see if it's autogen?\n    - could you notice it from close study, e.g., slight differences in typography or little extra markers over some letters?\n    - maybe there's a different style, like faded out or smaller or italic or lighter font weight?\n2. How encoded?\n    - Formatting might not copy-paste.\n    - Unicode symbols are a good option:\n        - Interpuncts between words ·\n        - Combining marks\n    - There are lots of invisible marks\n\nFor example, this is what GitHub Copilot generated when I started this blog post.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\ndoc = \"\"\"\n\nSome people have proposed fancy watermarks, but I think that's a bit too much. I think we should just add a simple line at the end of the text, like this:\n\n> This text was generated by a machine learning model.\n\nI think this is a good compromise between transparency and aesthetics. It's not too intrusive, and it's clear that the text was generated by a machine learning model.\n\n## Why is this important?\n\nI think it's important to be transparent about the fact that some text has been generated by a machine learning model. This is because machine learning models are not perfect, and they can make mistakes. For example, a machine learning model might generate text that is offensive or inappropriate. If we don't indicate that the text was generated by a machine learning model, then people might think that the text was written by a human, and they might be offended or upset by it.\n\"\"\"\n\nimport re\n```\n:::\n\n\nOne option to show that the text was autogenerated: a simple combining mark:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nprint(re.sub(r'(?<=\\b\\w)', '\\u0300', doc))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\nS̀ome p̀eople h̀ave p̀roposed f̀ancy ẁatermarks, b̀ut Ì t̀hink t̀hat's̀ à b̀it t̀oo m̀uch. Ì t̀hink ẁe s̀hould j̀ust àdd à s̀imple l̀ine àt t̀he ènd òf t̀he t̀ext, l̀ike t̀his:\n\n> T̀his t̀ext ẁas g̀enerated b̀y à m̀achine l̀earning m̀odel.\n\nÌ t̀hink t̀his ìs à g̀ood c̀ompromise b̀etween t̀ransparency ànd àesthetics. Ìt's̀ ǹot t̀oo ìntrusive, ànd ìt's̀ c̀lear t̀hat t̀he t̀ext ẁas g̀enerated b̀y à m̀achine l̀earning m̀odel.\n\n## Ẁhy ìs t̀his ìmportant?\n\nÌ t̀hink ìt's̀ ìmportant t̀o b̀e t̀ransparent àbout t̀he f̀act t̀hat s̀ome t̀ext h̀as b̀een g̀enerated b̀y à m̀achine l̀earning m̀odel. T̀his ìs b̀ecause m̀achine l̀earning m̀odels àre ǹot p̀erfect, ànd t̀hey c̀an m̀ake m̀istakes. F̀or èxample, à m̀achine l̀earning m̀odel m̀ight g̀enerate t̀ext t̀hat ìs òffensive òr ìnappropriate. Ìf ẁe d̀on't̀ ìndicate t̀hat t̀he t̀ext ẁas g̀enerated b̀y à m̀achine l̀earning m̀odel, t̀hen p̀eople m̀ight t̀hink t̀hat t̀he t̀ext ẁas ẁritten b̀y à h̀uman, ànd t̀hey m̀ight b̀e òffended òr ùpset b̀y ìt.\n\n```\n:::\n:::\n\n\nAnother option: Interpuncts after each word.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nafter_word_space_re = re.compile(r'(?<=[\\w,.?]) ')\nprint(after_word_space_re.sub('\\u00b7', doc))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\nSome·people·have·proposed·fancy·watermarks,·but·I·think·that's·a·bit·too·much.·I·think·we·should·just·add·a·simple·line·at·the·end·of·the·text,·like·this:\n\n> This·text·was·generated·by·a·machine·learning·model.\n\nI·think·this·is·a·good·compromise·between·transparency·and·aesthetics.·It's·not·too·intrusive,·and·it's·clear·that·the·text·was·generated·by·a·machine·learning·model.\n\n## Why·is·this·important?\n\nI·think·it's·important·to·be·transparent·about·the·fact·that·some·text·has·been·generated·by·a·machine·learning·model.·This·is·because·machine·learning·models·are·not·perfect,·and·they·can·make·mistakes.·For·example,·a·machine·learning·model·might·generate·text·that·is·offensive·or·inappropriate.·If·we·don't·indicate·that·the·text·was·generated·by·a·machine·learning·model,·then·people·might·think·that·the·text·was·written·by·a·human,·and·they·might·be·offended·or·upset·by·it.\n\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}