---
title: "Do I still need to learn that?"
description: "When should we learn vs just look it up?"
author: "Ken Arnold"
date: "2023-04-06"
categories: [ai, perspectival]
draft: true
---

If I can ask a chatbot any reasonable question and get the information I need, why should I bother trying to learn anything? Why pay kilobucks and years for a college degree to learn things, most of which will just get automated anyway?

Much has been written on this question, especially since Google became popular. So I'm not going to write a definitive piece here either. But I wanted to point out a few things that ChatGPT didn't mention when I asked it this question.

1. **Internalized skills are faster**. Suppose a child said "I don't need to learn to read, since my phone can just read things to me". Not untrue, but think about how much slower this kid would move through the world and process things if they had to ask their phone every time!
2. **Internalized skills are connected**. When we learn to read, we don't just learn to be able to turn images into words. We notice, without thinking, when some words are bigger, or drawn in a more playful style, or deliberately misspelled, or formed by arranging other objects into shapes. We can understand labeled diagrams and data graphics. We can use the shapes of letters as spatial analogies and references ("U-shaped", "at the corner of the L in the hallway").
3. **Knowledge begets knowledge**. Writing turns out to be mostly reading. People with certain cultural upbringings are able to solve problems by making analogies to those stories^[TODO: dig up this citation].
4. **Knowledge is discovered**. Chatbots can only report on, at best, what's already known. Living and loving in a changing world will require that we continue to question and advance the bounds of our collective knowledge.

In practice, I categorize my knowledge into two buckets:

- Things that I know and am glad I do ("*you should learn this too*")
- Things that I know and wish I didn't have to ("*you really shouldn't have to learn this*")

My second bucket is quite large, given the amount of experience I've had with quirky technical systems. But the first bucket is important: the more I learn there, the easier it is for me to learn something else. And the more I can take something that would have gone in the second bucket and actually get something more generally useful out of it.

So this, like many topics, requires discernment. I doubt that the quirks of the syntax of "regular expressions", especially how they vary between different programming languages and RE engines, will ever go in the top bucket for me. I'm happy to have a language model generate the specific RE for me based on my description of what it should match. But knowing the general idea of REs helps me recognize that (1) it's a tool I can use in circumstances like that, (2) when that tool is likely to fail (or the LM mis-generates it) and what to do about that, (3) how I might adjust earlier or later parts of the information flow to make the regex work better, and (4) recognizing when some other problem can be easily solved by reinterpreting it as matching a regular pattern.

So: what are the things that, when you know them, help you learn more new things? Central concepts that a lot of others connect to?
