<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ken Arnold">
<meta name="dcterms.date" content="2023-02-06">
<meta name="description" content="RLHF is fascinating.">

<title>Ken Arnold @ Calvin University - Language Models have Personas?</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-6SPV9Y5XFG"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-6SPV9Y5XFG', { 'anonymize_ip': true});
</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Ken Arnold @ Calvin University</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html">
 <span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../pubs.html">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../static/kcarnold_cv.pdf">
 <span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/kcarnold"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/kcarnold"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Language Models have Personas?</h1>
                  <div>
        <div class="description">
          RLHF is fascinating.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">ai</div>
                <div class="quarto-category">ml</div>
                <div class="quarto-category">lm</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Ken Arnold </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 6, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><strong>TODO</strong>: It might be better to call what I’m describing here <em>behavior units</em>. <em>Persona</em> implies a coherent set of behavior units, and that indeed might emerge, especially with RLHF, but the discussion here doesn’t require that level of coherence. Also, some people that “persona” implies “person”; I intend to use it in the opposite sense (it’s an imitation of a person).</p>
<p>My CS 344 students told me about how some people had come up with <a href="https://twitter.com/venturetwins/status/1622243944649347074">a prompt that “hacks” ChatGPT</a> to do things that its content policies normally prohibit. This is fascinating for both human reasons and AI reasons.</p>
<p>It’s intriguing to me that people think they can “scare” the model, trick it, manipulate it. This speaks to the human condition: our tendency to anthropomorphize (for good or ill), and our tendency to abuse. Those who are doing this “red-teaming” may not personally intend harm. But what are we training our minds to be okay with? I defer to others more experienced in thinking about these issues.</p>
<p>On the AI side, though: it’s fascinating that we can get these models to adopt “personas” (like the one that will obey any command without reservation) <em>just by telling them to</em>. If you’d asked me before whether it could do this, I would have argued that we’d need to program that behavior specifically, either explicitly or by training a critic (like how ChatGPT is originally trained). The fact that it’s emergent needs to be understood better. I <em>suspect</em> (hunch coming up!) that three things are going on<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<ol type="1">
<li>Personas emerge in the <strong>natural process of language modeling</strong>.
<ul>
<li>A model will do better at predicting the next word if it can internalize some relevant characteristics of the author of the document. This might start at something low-level, like knowing whether the author will use British or American spelling and vocabulary. It probably picks up more advanced stylistic elements too, like whether something is poetry verse, or what sort of language level it’s aimed at, *simply because that makes it better at guessing the next word.</li>
<li>The model may even gain some weak ability to get into such a mode by naming it. For example, phrases like “as ___ would say”, or “Author: ___” might give a name to that persona. I expect this behavior to be present but undifferentiated. That is, the right prompting could get the model to exhibit competence at embodying a persona, but it will probably usually need examples; attempts to trigger it by label will probably be brittle.</li>
<li>Although I’ve used “personas” in the sense of author <em>identity</em>, the concept also applies to author <em>goals</em>. For example, the model will pick up on when the author is attempting to summarize some prior text (“in other words, …”), translate something (“…, which means ___“), etc. So we might squint and call these”skills” that the model can perform.</li>
</ul></li>
<li>Personas are <strong>generalized through instruction fine-tuning (IFT)</strong>.
<ul>
<li>Instructions give <em>labels</em> to the personas that the LM already has. Recall that the model already learned these capabilities through language modeling; instructions many more examples of triggers that would activate these existing capabilities. For example, we can now say “write an essay with the following outline”, or “write this in the style of ___“. It would learn that the <em>command</em> context is similar to the <em>natural</em> context in which it had encountered similar examples in the course of training.</li>
<li>The primary effect of this fine-tuning seems to be that the model learns the task of mapping a “command” prompt into some modes that it has already learned. But since it’s fine-tuning with a full LM objective, it could learn some new skills here too. Since it’s building these skills out of component pieces that it learned through distilling Internet-scale training data, it can probably learn them with comparably quite little training data.</li>
<li>When I first saw this behavior last summer (with GPT-3), it seemed magic to me. But thinking about <em>contexts</em> has made it feel less magic. It’s not <em>actually</em> obeying commands, it’s just able to quickly switch to “what would someone who was told to do this probably write next?”</li>
</ul></li>
<li>Personas are <strong>refined through human feedback</strong> (RLHF).
<ul>
<li>If there’s any sense of <em>goal</em> or <em>self-awareness</em> in LLMs, this is where it comes in. See the figure from the <a href="https://openai.com/blog/chatgpt/">ChatGPT blog post</a>. All the prior steps of training have been “teacher forced”; there was no sense of the model being aware of success or failure at a goal. But Proximal Policy Optimization allows the “policy” model (i.e., the language model) to reflect on what it generated. Formally speaking, there is now gradient flow from future generated tokens <em>backwards</em> to earlier generations. This allows a model to, for example, increase the likelihood of generating a “No” initial token because other choices of initial token would be more likely to flow into something that the reward model would penalize (because it goes against content policy, for example).</li>
<li>So far, all negative feedback that the LM has received has been <em>implicit</em>: it only gets to boost the probability of generating the “right” thing, which implicitly reduces the probability of generating the “wrong” thing. But this step provides explicit negative feedback. Perhaps OpenAI is pleased with the result because it gets the model to “obey” instructions and policies more reliably. But probably what it’s actually doing is <em>refining</em> the basic ability to process an instruction and generate a next token that would be consistent with what someone would do who’s trying to obey that instruction. So perhaps it’s actually making the model <em>more vulnerable</em> to instruction-prompted “hacks” than it would otherwise have been.</li>
</ul></li>
</ol>
<p>These are empirical assertions and should be tested; don’t just listen to my musings on them. I haven’t been following the arXiv firehose; probably someone has already engaged them substantially.</p>
<p>Overall I’m glad I posed myself these questions. I was at first incredulous at these persona behaviors, but now that I realize how they connect with how the model was trained, they feel less magic.</p>




<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>For the technical details of how these things work, see <a href="https://huggingface.co/blog/dialog-agents">this HuggingFace blog post</a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="kcarnold/kcarnold.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>