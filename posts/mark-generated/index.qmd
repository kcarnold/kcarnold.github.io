---
title: "Transparency for Generated Text"
date: "2023-02-17"
categories: ["ml", "llm", "nlp"]
description: "Lightweight marks for AI-generated text"
featured: 1
---

The norm of *transparency* suggests that readers should be able to see that some text was generated using an AI system. But how should we indicate that some text has been automatically generated? Some have proposed fancy watermarks, but these have the potential for false positives, can be gamed, and aren't actually visible to humans without using a fancy tool. I think it's better if we make it easier for people to mark generated text, so easy that it would be the default.

A few dimensions in the design space:

1. How visible?
    - do you need to copy the text into a different tool to see if it's autogen?
    - could you notice it from close study, e.g., slight differences in typography or little extra markers over some letters?
    - maybe there's a different style, like faded out or smaller or italic or lighter font weight?
2. How encoded?
    - Formatting often doesn't copy-paste, especially in text messaging. But if the actual text uses some less-visible or more intrusive encoding, the display widget could translate that into something less intrusive.
    - Unicode symbols are a good option:
        - Interpuncts between words Â·, or some other [whitespace character](https://en.wikipedia.org/wiki/Whitespace_character)
        - [Combining characters](https://en.wikipedia.org/wiki/Combining_character) with some characters (but what about if the language actually uses these characters?)
    - There are lots of invisible marks in Unicode - search for Unicode Steganography. Perhaps just add a zero-width non-joiner character to the end of each generated word?
3. What gets marked?
    - Do we mark every generated character?
    - Every generated word?
    - Some generated words?
    - Proportional to how much information the model added (i.e., its total logprob?)
4. How does this relate to co-writing?

For example, this is what GitHub Copilot generated when I started this blog post.

```{python}
my_text = "Some people have proposed fancy watermarks, " 

completion = """but I think that's a bit too much. I think we should just add a simple line at the end of the text, like this:

> This text was generated by a machine learning model.

I think this is a good compromise between transparency and aesthetics. It's not too intrusive, and it's clear that the text was generated by a machine learning model.

## Why is this important?

I think it's important to be transparent about the fact that some text has been generated by a machine learning model. This is because machine learning models are not perfect, and they can make mistakes. For example, a machine learning model might generate text that is offensive or inappropriate. If we don't indicate that the text was generated by a machine learning model, then people might think that the text was written by a human, and they might be offended or upset by it.
"""

import re
```

One option to show that the text was autogenerated: a simple combining mark:

```{python}
print(my_text + re.sub(r'(?<=\b\w)', '\u0300', completion))
```

Another option: Interpuncts after each word.

```{python}
after_word_space_re = re.compile(r'(?<=[\w,.?]) ')
print(my_text + after_word_space_re.sub('\u00b7', completion))
```

Even if we use something like that to mark the text, we could still have it display the text in a visible way.

```{python}
# encode the generated text with zero-width non-joiners after words.
encoded_text = re.sub(r'(?<=\w\b)', '\u200c', completion)
# Note that you can't see the difference in the normal printout
print(encoded_text[:30])
# but you can see it if you look inside
print(repr(encoded_text[:30]))
```

```{python}
from IPython.display import HTML
def format_generated(match):
    word = match.group(1)
    return f'<span style="color: #999999;">{word}</span>'

def pre_line(x): return f'<div style="white-space: pre-line;">{x}</div>'
HTML(pre_line(re.sub(r'(\w+)\u200c', format_generated, encoded_text)))

```
