---
title: "Interacting with AI: X instead of Y"
date: "2024-03-28"
categories: ["ux", "ai"]
---

AI is typically designed in ways that push people aside, but what if we could reimagine the relationship?

**Writing**

The way that AI is currently used supports a view of writing as primarily about generating content. Instead, imagine AI tools guiding you through a document, offering feedback, and executing changes based on your specific instructions. This would empower writers rather than supplanting them.

**Making Decisions**

Sometimes AI systems are designed to make autonomous decisions about people, sometimes presented to people to endorse (verify). But AI could instead work in a collaborative mode, where it highlights aspects of the situation that people might not be considering, offers relevant precedents from historical data, and facilitates a more thoughtful and informed deliberation process without dictating the outcome.

**Learning and Teaching**

Instead of directly teaching people, replacing instructors or tutors, AI could be employed to serve *instructors* by helping them better understand what students are struggling with or excelling in, providing direction and feedback on educational materials, enabling new ways to differentiate instruction to meet diverse learners' needs, and providing qualitative feedback on teaching methods.

**Governance**

AI could transform governance by bringing the voices of diverse constituents into the decision-making process, even at points (like private committee meetings) where the individual people who might be affected by the decisions being made might normally be able to be present.


Other design considerations:

- Autocomplete: commands/style, not content
- Visualize complex collections and artifacts using *selective attention* not *select/summarize/regenerate*
- Provide control over *views* instead of *automatic* adjustments
- Blanks instead of guesses
- AI saying "what someone in this role might say" instead of taking on first-person personas
- AI checking and facilitating human work, not humans checking AI work.
    - suggestiong high-level editing actions instead of making the edits
    - visualizing examples / documentation instead of generating target content based on them.
    - help people identify faults that recent changes might have introduced
