[
  {
    "objectID": "posts/ml-gratitude/index.html",
    "href": "posts/ml-gratitude/index.html",
    "title": "Without Acknowledgment: Cultivating Gratitude in an ML age",
    "section": "",
    "text": "Generative AI tools can be really helpful for our creativity. Engaging with many and diverse examples has been shown to help human creativity; the systems themselves have engaged deeply with diverse examples and can fluently retrieve them for creators to use. But unlike when we a search engine, we can’t even acknowledge our inspiration if we want to. Rather than being able to give credit to a specific human author, or even to a creative team, the model makes us credit it, as the amalgamation of all of the human labor that it was trained on. The sheer scale of the data these models work with makes this hard: being trained on close to all human work becomes essentially the same as not being human work at all. If gratitude is a virtue, it seems like generative AI is positioned in opposition to it.\n\nLack of gratitude has been developing for a while. My students regularly write that they got some code “from StackOverflow” or got their data “from Kaggle” (note that they’re crediting the platform rather than the people); social media memes and quotes are copy-pasted without attribution. “Credit goes to the original authors” (without specifying who they are) exemplifies this trend.\nI’ve mainly seen this discussed in terms of copyright, which represents the perspective of the creator who rightly wants credit for their labor. But I’m pointing out here that the model isn’t serving the user either, if they want to practice gratitude in their creative work. Another related virtue is humility, exemplified by the phrase popularized by Isaac Newton of “standing on the shoulders of giants” (see that link for further tracing the source).\nIt’s most obvious in image generation models, where artists (rightly) complain that the model has appropriated their individual style without attribution. But text has the same issue; it’s just harder to notice how one piece of text is based on another, and text can be recomposed in so many different ways that it’s easy to dilute obvious influence.\n\nDoes it have to be this way? Yesterday I referenced an LM that tries to cite its sources for factual knowledge; citing sources for ideas and inspiration is technically and conceptually harder. But here are some things we might explore:\n\nInstead of treating the task as generating a complete outcome, what if the system’s goal were to retrieve a curated set of inspirational examples? There’s some good academic work on this using older AI techniques; perhaps we can upgrade that.\nCan we query an LM to ask what items in its training data were most helpful in constructing an example? This has some relationships with interpretability and explainability literature, but academic work there tends to be focused on explaining a single decision, rather than the sequence of decisions that leads to a generated text or image.\n\nRetrieval-oriented LMs help with this a lot for factual content, but don’t really work for style, I’m guessing.\nSimple approach would be to query the training data for examples with similar embeddings for the current token. I saw some then-Facebook Research papers on this a while back. But that’s a single token, not a phrase.\nPerhaps we can sample forward from a hidden state to get a sense of: contexts are similar if they lead to similar generations.\nA different direction could be augmenting the training process with some aux output that is then used for retrieval."
  },
  {
    "objectID": "posts/knowledge-fusion/index.html",
    "href": "posts/knowledge-fusion/index.html",
    "title": "Language Models for Species-Scale Collaboration",
    "section": "",
    "text": "Large lanugage models like ChatGPT (and its peers like PaLM, BLOOMZ, etc.) are surprisingly powerful tools for knowledge fusion. For example, if I ask GPT-3 to continue “A list of exercises for beginning computer science students: 1.”, it will generate that list based on all exercises that ever have been listed in plausibly similar contexts. Communities of practice have been exchanging ideas and knowledge throughout human history, but the tools and scale have increased with technological developments like the printing press, video capture, and the Internet, and social developments like academic conferences and social media. Language models are continuing the trend of increasing knowledge sharing by becoming, in a sense, dynamic summaries of slices of others’ ideas. Like reading a textbook or a review article, we can benefit from the insights and ideas of others without directly having to read them. But it can do this without nearly as much human effort as writing such reviews."
  },
  {
    "objectID": "posts/knowledge-fusion/index.html#implications",
    "href": "posts/knowledge-fusion/index.html#implications",
    "title": "Language Models for Species-Scale Collaboration",
    "section": "Implications",
    "text": "Implications\n\nWe’ll be able to collaborate at even greater scales than before. AI systems will help cross-pollinate ideas between disparate communities of practice. Instructors will still make our own educational materials, for example, but instead of blank pages, we’ll start with ideas synthesized from everyone else who’s ever taught a related subject.\nBut, LMs will need to get better at citing their sources. There’s thankfully some work going on in that area: Attributed Question Answering: Evaluation and Modeling for Attributed Large Language Models | Abstract\nAnd: since LMs conflate popularity (i.e., what’s common) with quality—and that’s really tricky to untangle—we’ll need more discernment about when, and when not, to seek and use LM suggestions."
  },
  {
    "objectID": "posts/knowledge-fusion/index.html#related",
    "href": "posts/knowledge-fusion/index.html#related",
    "title": "Language Models for Species-Scale Collaboration",
    "section": "Related",
    "text": "Related\n\nMargaret Boden, Computer Models of Creativity | AI Magazine"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ken Arnold",
    "section": "",
    "text": "I’m interested in research and teaching at the intersection of data science, people, and Christian faith.\nMy main projects are around AI for Everyday Creativity, including:"
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Ken Arnold",
    "section": "Recent Posts",
    "text": "Recent Posts\n\n\n\n\n\n\nWithout Acknowledgment: Cultivating Gratitude in an ML age\n\n\n\n\nCreativity support tools based on machine learning hide the human authors that contributed to the work. Does it have to be that way?\n\n\n\n\n\n\nJan 12, 2023\n\n\nKen Arnold\n\n\n\n\n\n\n\n\nLanguage Models for Species-Scale Collaboration\n\n\n\n\nHow knowledge fusion will continue the trend of scaling humam collaboration\n\n\n\n\n\n\nJan 11, 2023\n\n\nKen Arnold\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "Ken Arnold",
    "section": "Teaching",
    "text": "Teaching\nI teach computer science, data science, and machine learning. Recent classes:\n\nDATA 202 Data Science 2, a data wrangling, predictive modeling, and visualization course using the R tidyverse, with a project emphasis\nCS 344 Artificial Intelligence, a hands-on (but also concept-heavy) machine learning course based on the fast.ai course and Hugging Face Transformers\nCS 108 Introduction to Computing and CS 106, Calvin’s first-year Computer Science course, in Python.\nINFO 602 Predictive Analytics (for Calvin’s MBA program)\n\nSee CV for others."
  },
  {
    "objectID": "index.html#doing-research-with-me",
    "href": "index.html#doing-research-with-me",
    "title": "Ken Arnold",
    "section": "Doing research with me",
    "text": "Doing research with me\nI welcome students who are interested in human-computer interaction, machine learning, data science, interactive visualization, and Christian perspectives on data and computation. I have a range of ideas and ongoing projects, but bring your own interests too! Please contact me via email (Calvin: ka37) or Teams."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Ken Arnold",
    "section": "Education",
    "text": "Education\n\nPhD in Computer Science, Harvard, 2020\nMS in Media Arts and Sciences, MIT, 2010\nBS in Electrical and Computer Engineering, Cornell, 2007"
  },
  {
    "objectID": "pubs.html",
    "href": "pubs.html",
    "title": "Publications",
    "section": "",
    "text": "Some selected publications are below. For a more complete list, see my Google Scholar profile\n\n\n\n\n\n\n\n\n  \n\n\n\n\nSentiment Bias in Predictive Text Recommendations Results in Biased Writing\n\n\n\n\n\nIntelligent systems make biased decisions because they are trained on biased data. Could these system biases affect what people create? We found that when writing restaurant reviews, biased system behavior leads to biased human behavior: People presented with phrasal text entry shortcuts that were skewed positive wrote more positive reviews than they did when presented with negative-skewed shortcuts.\n\n\n\n\n\n\nMay 8, 2018\n\n\n\n\n\n\n  \n\n\n\n\nOn Suggesting Phrases vs. Predicting Words for Mobile Text Composition\n\n\n\n\n\nWe introduce a simple extension to the familiar mobile keyboard suggestion interface that presents phrase suggestions that can be accepted by a repeated-tap gesture. In an extended composition task, we found that phrases were interpreted as suggestions that affected the content of what participants wrote more than conventional single-word suggestions, which were interpreted as predictions.\n\n\n\n\n\n\nOct 16, 2016\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "static/new_years_2020/new_years_2020.html",
    "href": "static/new_years_2020/new_years_2020.html",
    "title": "Arnolds New Years Letter 2020",
    "section": "",
    "text": "Happy New Decade!\nHighlights:\n\nWe’ve moved to Grand Rapids, Michigan! We miss Boston and our friends there (who helped us immensely with the move, by the way), but we’ve started to appreciate Grand Rapids on its own terms.\nKen started teaching Computer Science and Data Science at Calvin University! The first semester was joyfully overwhelming. Ken feels increasingly thankful and blessed to be there.\nSusan has mostly been at home with Naomi and Esther. For ten weeks last spring, she went back to work part time for her former architecture firm, with the help of a wonderful nanny. She felt like that was a nice balance and is hoping to find a similar part time schedule here, once she finishes her architecture professional exams.\nNaomi and Esther celebrated their second birthday in November. They have learned so much, going from not talking at the beginning of the year, to putting ever more complex phrases together.\n\nOther tidbits:\n\n2019 started with a New Year’s Day hike in Maryland with Ken’s brother Austin and (now) fiancée Mason, and finished with Ken’s parents visiting us in Grand Rapids for New Years 2020.\nKen’s parents visited us frequently during the year (coming from Maryland) and Susan’s parents visited Boston over the summer to help us pack up for our move.\nNaomi and Esther were baptized at Citylife Church in Boston in June, with all grandparents attending. Baptism is a symbol of the faith we share and our hopes that the girls will grow in that faith as part of Christian community.\nWe enjoyed Christmas in Portland, Oregon with Susan’s parents.\nWe are now located closer to Susan’s extended family in Michigan.\nWe bought a minivan (a like-new Honda Odyssey)!\n\nLooking forward to:\n\nKen teaching another two classes this spring, and hopefully finally defending his PhD thesis (long story).\nUpcoming travels: to Ken’s brother Austin’s wedding mid-October, Ken traveling to Italy in March to present a paper at a conference (it finally got accepted on the third try), and maybe a few days vacationing by Lake Michigan this summer with one of Susan’s friends.\nGetting connected with a local church.\nSusan continuing in professional development and maybe starting work.\nNaomi and Esther continuing to grow, and we’re considering starting preschool this year.\n\nOur new address is 3654 Palmer Ridge Road SE, Grand Rapids MI 49546.\nWith love,\nKen, Susan, Esther and Naomi\n\n\n\nNaomi and Esther\n\n\nmore photos here."
  },
  {
    "objectID": "pubs/sentiment-bias/index.html",
    "href": "pubs/sentiment-bias/index.html",
    "title": "Sentiment Bias in Predictive Text Recommendations Results in Biased Writing",
    "section": "",
    "text": "PDF In GI’18"
  },
  {
    "objectID": "pubs/sentiment-bias/index.html#abstract",
    "href": "pubs/sentiment-bias/index.html#abstract",
    "title": "Sentiment Bias in Predictive Text Recommendations Results in Biased Writing",
    "section": "Abstract",
    "text": "Abstract\nPrior research has demonstrated that intelligent systems make biased decisions because they are trained on biased data. As people increasingly leverage intelligent systems to enhance their productivity and creativity, could system biases affect what people create? We demonstrate that in at least one domain (writing restaurant reviews), biased system behavior leads to biased human behavior: People presented with phrasal text entry shortcuts that were skewed positive wrote more positive reviews than they did when presented with negative-skewed shortcuts. This result contributes to the pertinent debate about the role of intelligent systems in our society."
  },
  {
    "objectID": "pubs/phrase-suggestion/index.html",
    "href": "pubs/phrase-suggestion/index.html",
    "title": "On Suggesting Phrases vs. Predicting Words for Mobile Text Composition",
    "section": "",
    "text": "PDF In UIST’16"
  },
  {
    "objectID": "pubs/phrase-suggestion/index.html#abstract",
    "href": "pubs/phrase-suggestion/index.html#abstract",
    "title": "On Suggesting Phrases vs. Predicting Words for Mobile Text Composition",
    "section": "Abstract",
    "text": "Abstract\nA system capable of suggesting multi-word phrases while someone is writing could supply ideas about content and phrasing and allow those ideas to be inserted efficiently. Meanwhile, statistical language modeling has provided various approaches to predicting phrases that users type. We introduce a simple extension to the familiar mobile keyboard suggestion interface that presents phrase suggestions that can be accepted by a repeated-tap gesture. In an extended composition task, we found that phrases were interpreted as suggestions that affected the content of what participants wrote more than conventional single-word suggestions, which were interpreted as predictions. We highlight a design challenge: how can a phrase suggestion system make valuable suggestions rather than just accurate predictions?"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "AI for Everyday Creativity",
    "section": "",
    "text": "Without Acknowledgment: Cultivating Gratitude in an ML age\n\n\n\n\n\n\n\nai\n\n\nml\n\n\nlm\n\n\nia\n\n\n\n\nCreativity support tools based on machine learning hide the human authors that contributed to the work. Does it have to be that way?\n\n\n\n\n\n\nJan 12, 2023\n\n\nKen Arnold\n\n\n\n\n\n\n\n\nLanguage Models for Species-Scale Collaboration\n\n\n\n\n\n\n\nai\n\n\nml\n\n\nlm\n\n\nia\n\n\n\n\nHow knowledge fusion will continue the trend of scaling humam collaboration\n\n\n\n\n\n\nJan 11, 2023\n\n\nKen Arnold\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "bio.html",
    "href": "bio.html",
    "title": "Bios",
    "section": "",
    "text": "Assistant professor of computer science and data science at Calvin University. Crafting tools to augment intelligence, teaching students to build and use tech wisely."
  },
  {
    "objectID": "bio.html#medium50-words",
    "href": "bio.html#medium50-words",
    "title": "Bios",
    "section": "Medium(50 words)",
    "text": "Medium(50 words)\nKen Arnold (B.S., Cornell; M.S., MIT; Ph.D., Harvard) is an assistant professor of computer science and data science at Calvin University. His research has shown how predictive text interfaces, like those in smartphone keyboards and email apps, can shape the content of what people communicate. His current research interests include human-AI interaction in communication, creativity, and education."
  },
  {
    "objectID": "bio.html#longer",
    "href": "bio.html#longer",
    "title": "Bios",
    "section": "Longer",
    "text": "Longer\nKen Arnold (B.S., Cornell; M.S., MIT; Ph.D., Harvard) is an assistant professor of computer science and data science at Calvin University. His research has shown how predictive text interfaces, like those in smartphone keyboards and email apps, can shape the content of what people communicate. He is currently working on intelligence augmentation to help writers craft words that are fully their own. His current research interests include human-AI interaction in communication, creativity, and education."
  }
]