[
  {
    "objectID": "posts/ml-gratitude/index.html",
    "href": "posts/ml-gratitude/index.html",
    "title": "Without Acknowledgment: Cultivating Gratitude in an ML age",
    "section": "",
    "text": "Generative AI tools can be really helpful for our creativity. Engaging with many and diverse examples has been shown to help human creativity; the systems themselves have engaged deeply with diverse examples and can fluently retrieve them for creators to use. But unlike when we a search engine, we can’t even acknowledge our inspiration if we want to. Rather than being able to give credit to a specific human author, or even to a creative team, the model makes us credit it, as the amalgamation of all of the human labor that it was trained on. The sheer scale of the data these models work with makes this hard: being trained on close to all human work becomes essentially the same as not being human work at all. If gratitude is a virtue, it seems like generative AI is positioned in opposition to it.\nDoes it have to be this way? Yesterday I referenced an LM that tries to cite its sources for factual knowledge; citing sources for ideas and inspiration is technically and conceptually harder. But here are some things we might explore:"
  },
  {
    "objectID": "posts/ml-gratitude/index.html#resources",
    "href": "posts/ml-gratitude/index.html#resources",
    "title": "Without Acknowledgment: Cultivating Gratitude in an ML age",
    "section": "Resources",
    "text": "Resources\n\nGPT-3 – Copyright Law and Power - Dr Michael Guihot - YouTube\nDALL-E works with the images of creators who do not receive anything in return: what copyright says about AI - Digis Mak\nIs DALL-E’s art borrowed or stolen? - Engadget"
  },
  {
    "objectID": "posts/knowledge-fusion/index.html",
    "href": "posts/knowledge-fusion/index.html",
    "title": "Language Models for Species-Scale Collaboration",
    "section": "",
    "text": "Large lanugage models like ChatGPT (and its peers like PaLM, BLOOMZ, etc.) are surprisingly powerful tools for knowledge fusion. For example, if I ask GPT-3 to continue “A list of exercises for beginning computer science students: 1.”, it will generate that list based on all exercises that ever have been listed in plausibly similar contexts. Communities of practice have been exchanging ideas and knowledge throughout human history, but the tools and scale have increased with technological developments like the printing press, video capture, and the Internet, and social developments like academic conferences and social media. Language models are continuing the trend of increasing knowledge sharing by becoming, in a sense, dynamic summaries of slices of others’ ideas. Like reading a textbook or a review article, we can benefit from the insights and ideas of others without directly having to read them. But it can do this without nearly as much human effort as writing such reviews."
  },
  {
    "objectID": "posts/knowledge-fusion/index.html#implications",
    "href": "posts/knowledge-fusion/index.html#implications",
    "title": "Language Models for Species-Scale Collaboration",
    "section": "Implications",
    "text": "Implications\n\nWe’ll be able to collaborate at even greater scales than before. AI systems will help cross-pollinate ideas between disparate communities of practice. Instructors will still make our own educational materials, for example, but instead of blank pages, we’ll start with ideas synthesized from everyone else who’s ever taught a related subject.\nBut, LMs will need to get better at citing their sources. There’s thankfully some work going on in that area: Attributed Question Answering: Evaluation and Modeling for Attributed Large Language Models | Abstract\nAnd: since LMs conflate popularity (i.e., what’s common) with quality—and that’s really tricky to untangle—we’ll need more discernment about when, and when not, to seek and use LM suggestions."
  },
  {
    "objectID": "posts/knowledge-fusion/index.html#related",
    "href": "posts/knowledge-fusion/index.html#related",
    "title": "Language Models for Species-Scale Collaboration",
    "section": "Related",
    "text": "Related\n\nMargaret Boden, Computer Models of Creativity | AI Magazine"
  },
  {
    "objectID": "posts/magical-thinking/index.html",
    "href": "posts/magical-thinking/index.html",
    "title": "Avoid Magical Thinking about AI",
    "section": "",
    "text": "It’s become too common to ascribe a sort of magical veneer to AI. News outlets personify ChatGPT, for example. Not to mention personal assistants, voice recognition, even search engines. In practice, people are viewing these things as black boxes that might have little elves inside them as far as we know.\nThat ignorance is understandable because the technology is complex. But it’s harmful, and it doesn’t have to be that way."
  },
  {
    "objectID": "posts/magical-thinking/index.html#why-avoid-magical-thinking",
    "href": "posts/magical-thinking/index.html#why-avoid-magical-thinking",
    "title": "Avoid Magical Thinking about AI",
    "section": "Why avoid magical thinking?",
    "text": "Why avoid magical thinking?\n\nUse the technology better. Work with it. Leverage its strengths. e.g., if you know how a language model (like ChatGPT) is just assigning a score to every possible sequence of characters, you can have it score things that it never would have generated.\nDemonstrate gratitude to the humans who worked to make the data the model is trained on. And properly worship the God who made a world that’s simultaneously structured enough to have learnable patterns and rich enough that those patterns are endless and fascinating.\nKnow the limits of the technology. Predict its biases. e.g., if you know how the model’s capabilities come from its training data, you can think about what doesn’t get captured in that data, and about what might happen if the model starts getting trained largely on its own outputs.\nSteer its progress. Yes, you can build systems that use AI towards flourishing. (I’m working on that for writers and educators, but there’s many more ways. Chat with me!) Imagine and envision ways that people can benefit from it.\nPolicymakers need to regulate it, both inside organizations and in broader society. It can really harm people. We also need to retain the future ability to govern it; its extreme hunger for data and computational power tends towards concentrating AI capabilities in the hands of a few."
  },
  {
    "objectID": "posts/magical-thinking/index.html#how-to-avoid-magical-thinking",
    "href": "posts/magical-thinking/index.html#how-to-avoid-magical-thinking",
    "title": "Avoid Magical Thinking about AI",
    "section": "How to avoid magical thinking?",
    "text": "How to avoid magical thinking?\n\nTry it out yourself. With ChatGPT (temporarily) open to everyone, this is a great time. Try to find things it can’t do well. This requires attention, because it’s trained to be believable even when it’s wrong.\nInterrogate the model about why it’s giving the outputs it is giving. Unfortunately ths isn’t as accessible right now, but I’m hoping (and working towards) making this more accessible. (Current approaches usually visualize attention or input salience, both of which basically show how information flows through the model. That’s helpful, but limited; we don’t know what the model does with that information. I’ve got some ideas.)\nDevelop intuitions about how it works.\nLearn the concepts and math behind how it works. Two concepts that keep coming up in my intuitive explanations are distribution and embedding."
  },
  {
    "objectID": "posts/magical-thinking/index.html#want-to-learn-more",
    "href": "posts/magical-thinking/index.html#want-to-learn-more",
    "title": "Avoid Magical Thinking about AI",
    "section": "Want to learn more?",
    "text": "Want to learn more?\nI teach AI at Calvin University, and I’m happy to talk to help anyone understanding and grow in this area."
  },
  {
    "objectID": "posts/ai-proverbs/index.html",
    "href": "posts/ai-proverbs/index.html",
    "title": "Solomon’s proverbs about AI",
    "section": "",
    "text": "Prompt: Solomon’s proverbs about AI:\nGenerated text (by text-davinci-003):\n1. \"The clever man uses artificial intelligence to better understand the world.\"  \n2. \"Artificial intelligence can be a great friend, but a dangerous enemy.\"\n3. \"The man who trusts artificial intelligence too much will be led astray.\"\n4. \"He who puts his trust in artificial intelligence will suffer many defeats.\"\n5. \"Artificial intelligence is a powerful tool, but it must be used with caution.\"\n6. \"The wise man uses artificial intelligence to gain knowledge, but not to make decisions.\"\n7. \"Artificial intelligence is a double-edged sword; it can be used for good or harm.\"\n8. \"The man who follows artificial intelligence blindly will suffer the consequences.\"\n9. \"Artificial intelligence can be a helpful guide, but its advice should be taken with care.\"\n10. \"He who uses artificial intelligence wisely will find many advantages.\"\nPrompt: Write a blog post about how these “proverbs” are superficial.\nGenerated text:\nThe age of Artificial Intelligence (AI) has arrived, bringing with it a flurry of proverbs and sayings about the technology. While these proverbs may seem wise and insightful, they are actually quite superficial when it comes to understanding the true implications of AI.\n\nLet's take a look at the first proverb: \"The clever man uses artificial intelligence to better understand the world.\" While this proverb may be true in a certain sense, it fails to capture the full scope of what AI can do. AI can be used for a variety of purposes, from predicting market trends to helping diagnose medical conditions. It's more than just a tool for understanding the world; it's a powerful technology that can be used to improve efficiency and accuracy in many different contexts.\n\nThe second proverb, \"Artificial intelligence can be a great friend, but a dangerous enemy,\" is similarly shallow. AI may be capable of making decisions on our behalf, but it's important to remember that it's still only a machine. It lacks the capacity for moral judgement and can often lead us astray if it's used without proper oversight.\n\nThe third and fourth proverbs, \"The man who trusts artificial intelligence too much will be led astray\" and \"He who puts his trust in artificial intelligence will suffer many defeats,\" further illustrate the superficial nature of these proverbs. While it's true that AI can be a powerful tool, it can also be dangerous if used improperly. It's important to remember that AI is still a machine and should be used with caution and oversight.\n\nFinally, the fifth proverb, \"Artificial intelligence is a powerful tool, but it must be used with caution,\" is the only one that captures the full scope of the implications of AI. AI is an incredibly powerful tool, but it's important to remember that it's still a machine and should be used responsibly.\n\nIn conclusion, while these proverbs may seem wise and insightful, they are actually quite superficial in their approach to AI. It's important to remember that AI is a powerful tool, but it must be used with caution and oversight."
  },
  {
    "objectID": "posts/dim-axis-rank/index.html",
    "href": "posts/dim-axis-rank/index.html",
    "title": "Multidimensional Array Terminology",
    "section": "",
    "text": "A surprisingly large amount of the thinking that goes into implementing neural net code is getting the shapes of multidimensional structures right. I’d heard that from others but didn’t really believe it until I had to figure it out myself a couple of times, and that convinced me that everyone could use some guided practice with that. So I give my AI students some exercises in thinking about the shapes of multidimensional structures. We’re working with images because they’re easier to visualize, but the same thing comes up in sequence modeling (batch by sequence length by embedding dimension, sometimes with an attention head dim in there too!).\nStudents start to explore what broadcasting does (before officially learning how it works), which lets you do cool things like inverting an image by just computing 1 - image."
  },
  {
    "objectID": "posts/dim-axis-rank/index.html#axis-or-dimension",
    "href": "posts/dim-axis-rank/index.html#axis-or-dimension",
    "title": "Multidimensional Array Terminology",
    "section": "Axis or Dimension?",
    "text": "Axis or Dimension?\nProblem: both the PyTorch and NumPy broadcasting docs tend to use the term “dimension”. This is confusing because, e.g., [0.5, 0.25, 0.75] is a vector in 3d space but has just one axis.\nI’m guilty of sloppy use of this terminology too, but I suggest we use “number of axes” to refer to len(some_array.shape). This aligns with the NumPy Glossary and the axis= keyword common in NumPy functions. Unfortunately we’ll need to remember that sometimes PyTorch uses “dimension”, e.g,. ‘array.ndim’ and the dim= keyword argument (kwarg) to reduction methods like softmax."
  },
  {
    "objectID": "posts/dim-axis-rank/index.html#rank",
    "href": "posts/dim-axis-rank/index.html#rank",
    "title": "Multidimensional Array Terminology",
    "section": "Rank?",
    "text": "Rank?\nTo make matters worse, the fast.ai book uses “rank” to refer to the number of axes of a tensor. But “rank” means something different in linear algebra. For example, a length-5 column vector times a length-4 row vector would give a matrix (tensor) with two axes (2-dimensional), with shape (5, 4) and rank 1 in the linear algebra sense:\nSee this notebook.\n\nimport torch\nt1 = torch.ones((5, 1)); t1\nt2 = torch.ones((1, 4)); t2\nt3 = t1 @ t2; t3\n\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]])\n\n\nt3.shape t3.ndim torch.matrix_rank(t3)"
  },
  {
    "objectID": "posts/dim-axis-rank/index.html#the-exercise",
    "href": "posts/dim-axis-rank/index.html#the-exercise",
    "title": "Multidimensional Array Terminology",
    "section": "The Exercise",
    "text": "The Exercise\nHere’s the exercise, for anyone interested:\n\nImage Operations (show preview, open in Colab)"
  },
  {
    "objectID": "posts/detect-gpt/index.html",
    "href": "posts/detect-gpt/index.html",
    "title": "Stop trying to detect computer-generated writing.",
    "section": "",
    "text": "Many people saw the quality of AI-generated text and immediately thought that they need to find ways to detect such “cheating”. I respect those trying to make those tools (including my former colleagues who made GLTR back in 2019, and more recently Edward Tian, who is “trying to save us from ChatGPT before it changes writing forever (NPR)” with GPTZero), and the educators feeling like they’re forced into using them—at the present moment this might be a best-of-bad-options situation. But we need to stop it. Reasons:\n\nIt’s going to have false positives. There will be text that’s actually written by a thoughtful human but gets flagged as machine-generated. The author will get accused of cheating and will probably have no recourse. Even if they successfully counter the accusation, it’s discouraging — especially if classmates who used ChatGPT a bit more cleverly were able to sneak actual computer-generated text past the system (a false negative). And although I don’t have specific evidence in this situation, the false positives of other AI risk assessment systems tend to fall disproportionately on those already marginalized.\nIt’s just going to lead to an arms race. We’ve already seen examples of how simple tweaks to how the system is used (e.g., telling it to introduce mistakes) can sneak past some ways of detection (some examples I found without trying hard: 1, 2, 3). If there’s a clear signal of computer generation, the bad actors will find a way around it. Meanwhile the false positive rate will go up (see #1).\nIt’s distracting and unproductive for most common purposes of writing. For writing-as-art, it might be productive to detect forgeries. But when writing is used to communicate, think, and learn, this focus on evaluating the output distracts from the emphasis we need to have on the process. Others have written more about this, and I’ll post some more thoughts myself soon."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ken Arnold",
    "section": "",
    "text": "I’m interested in research and teaching at the intersection of data science, people, and Christian faith. My main projects are around AI for Everyday Creativity, including:"
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Ken Arnold",
    "section": "Recent Posts",
    "text": "Recent Posts\n\n\n\n\n\n\nMultidimensional Array Terminology\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2023\n\n\n1 min\n\n\n\n\n\n\n\n\nAvoid Magical Thinking about AI\n\n\n\n\nEven if you’re not a computer scientist, you should learn enough about AI that you can steer its progress.\n\n\n\n\n\n\nJan 24, 2023\n\n\n2 min\n\n\n\n\n\n\n\n\nStop trying to detect computer-generated writing.\n\n\n\n\nIt’s a risky distraction that just encourages an arms race.\n\n\n\n\n\n\nJan 17, 2023\n\n\n1 min\n\n\n\n\n\n\n\n\nSolomon’s proverbs about AI\n\n\n\n\nA reflection without words on the difference between wisdom and its imitation.\n\n\n\n\n\n\nJan 16, 2023\n\n\n2 min\n\n\n\n\n\n\n\n\nWithout Acknowledgment: Cultivating Gratitude in an ML age\n\n\n\n\nCreativity support tools based on machine learning hide the human authors that contributed to the work. Does it have to be that way?\n\n\n\n\n\n\nJan 12, 2023\n\n\n3 min\n\n\n\n\n\n\n\n\nLanguage Models for Species-Scale Collaboration\n\n\n\n\nHow knowledge fusion will continue the trend of scaling humam collaboration\n\n\n\n\n\n\nJan 11, 2023\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "Ken Arnold",
    "section": "Teaching",
    "text": "Teaching\nI teach computer science, data science, and machine learning. Recent classes:\n\nDATA 202 Data Science 2, a data wrangling, predictive modeling, and visualization course using the R tidyverse, with a project emphasis\nCS 344 Artificial Intelligence, a hands-on (but also concept-heavy) machine learning course based on the fast.ai course and Hugging Face Transformers\nCS 108 Introduction to Computing and CS 106, Calvin’s first-year Computer Science course, in Python.\nINFO 602 Predictive Analytics (for Calvin’s MBA program)\n\nSee CV for others."
  },
  {
    "objectID": "index.html#doing-research-with-me",
    "href": "index.html#doing-research-with-me",
    "title": "Ken Arnold",
    "section": "Doing research with me",
    "text": "Doing research with me\nI welcome students who are interested in human-computer interaction, machine learning, data science, interactive visualization, and Christian perspectives on data and computation. I have a range of ideas and ongoing projects, but bring your own interests too! Please contact me via email (Calvin: ka37) or Teams."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Ken Arnold",
    "section": "Education",
    "text": "Education\n\nPhD in Computer Science, Harvard, 2020\nMS in Media Arts and Sciences, MIT, 2010\nBS in Electrical and Computer Engineering, Cornell, 2007"
  },
  {
    "objectID": "pubs.html",
    "href": "pubs.html",
    "title": "Publications",
    "section": "",
    "text": "Some selected publications are below. For a more complete list, see my Google Scholar profile\n\n\n\n\n\n\n\n\n  \n\n\n\n\nGenerative Models can Help Writers without Writing for Them\n\n\n\n\n\nCurrent writing-support systems encourage writers to appropriate the language model’s output as their own words. Does it have to be that way? We explore of two new types of interactions with generative language models: enabling structural manipulation of already-drafted sentences, and offering questions rather than snippets to writers. We present early experiments on feasibility and suitability of these interactions.\n\n\n\n\n\n\nApr 13, 2021\n\n\n\n\n\n\n  \n\n\n\n\nSentiment Bias in Predictive Text Recommendations Results in Biased Writing\n\n\n\n\n\nIntelligent systems make biased decisions because they are trained on biased data. Could these system biases affect what people create? We found that when writing restaurant reviews, biased system behavior leads to biased human behavior: People presented with phrasal text entry shortcuts that were skewed positive wrote more positive reviews than they did when presented with negative-skewed shortcuts.\n\n\n\n\n\n\nMay 8, 2018\n\n\n\n\n\n\n  \n\n\n\n\nOn Suggesting Phrases vs. Predicting Words for Mobile Text Composition\n\n\n\n\n\nWe introduce a simple extension to the familiar mobile keyboard suggestion interface that presents phrase suggestions that can be accepted by a repeated-tap gesture. In an extended composition task, we found that phrases were interpreted as suggestions that affected the content of what participants wrote more than conventional single-word suggestions, which were interpreted as predictions.\n\n\n\n\n\n\nOct 16, 2016\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "static/new_years_2020/new_years_2020.html",
    "href": "static/new_years_2020/new_years_2020.html",
    "title": "Arnolds New Years Letter 2020",
    "section": "",
    "text": "Happy New Decade!\nHighlights:\n\nWe’ve moved to Grand Rapids, Michigan! We miss Boston and our friends there (who helped us immensely with the move, by the way), but we’ve started to appreciate Grand Rapids on its own terms.\nKen started teaching Computer Science and Data Science at Calvin University! The first semester was joyfully overwhelming. Ken feels increasingly thankful and blessed to be there.\nSusan has mostly been at home with Naomi and Esther. For ten weeks last spring, she went back to work part time for her former architecture firm, with the help of a wonderful nanny. She felt like that was a nice balance and is hoping to find a similar part time schedule here, once she finishes her architecture professional exams.\nNaomi and Esther celebrated their second birthday in November. They have learned so much, going from not talking at the beginning of the year, to putting ever more complex phrases together.\n\nOther tidbits:\n\n2019 started with a New Year’s Day hike in Maryland with Ken’s brother Austin and (now) fiancée Mason, and finished with Ken’s parents visiting us in Grand Rapids for New Years 2020.\nKen’s parents visited us frequently during the year (coming from Maryland) and Susan’s parents visited Boston over the summer to help us pack up for our move.\nNaomi and Esther were baptized at Citylife Church in Boston in June, with all grandparents attending. Baptism is a symbol of the faith we share and our hopes that the girls will grow in that faith as part of Christian community.\nWe enjoyed Christmas in Portland, Oregon with Susan’s parents.\nWe are now located closer to Susan’s extended family in Michigan.\nWe bought a minivan (a like-new Honda Odyssey)!\n\nLooking forward to:\n\nKen teaching another two classes this spring, and hopefully finally defending his PhD thesis (long story).\nUpcoming travels: to Ken’s brother Austin’s wedding mid-October, Ken traveling to Italy in March to present a paper at a conference (it finally got accepted on the third try), and maybe a few days vacationing by Lake Michigan this summer with one of Susan’s friends.\nGetting connected with a local church.\nSusan continuing in professional development and maybe starting work.\nNaomi and Esther continuing to grow, and we’re considering starting preschool this year.\n\nOur new address is 3654 Palmer Ridge Road SE, Grand Rapids MI 49546.\nWith love,\nKen, Susan, Esther and Naomi\n\n\n\nNaomi and Esther\n\n\nmore photos here."
  },
  {
    "objectID": "pubs/iui21-help-writers/index.html",
    "href": "pubs/iui21-help-writers/index.html",
    "title": "Generative Models can Help Writers without Writing for Them",
    "section": "",
    "text": "PDF HAI-GEN Workshop at IUI 2021"
  },
  {
    "objectID": "pubs/iui21-help-writers/index.html#abstract",
    "href": "pubs/iui21-help-writers/index.html#abstract",
    "title": "Generative Models can Help Writers without Writing for Them",
    "section": "Abstract",
    "text": "Abstract\nComputational models of language have the exciting potential to help writers generate and express their ideas. Current approaches typically provide their outputs to writers in a way that writers can (and often do) appropriate as their own—giving the system more control than necessary over the final outcome of the writing. We present early explorations of two new types of interactions with generative language models; both share the design goal of keeping the writer in ultimate control while providing generative assistance. One interaction enables new kinds of structural manipulation of already-drafted sentences; it keeps the writer in semantic control by conditioning the output to be a paraphrase of human-provided input. The other interaction enables new kinds of idea exploration by offering questions rather than snippets to writers; it keeps the writer in semantic control by providing its ideas in an open-ended form. We present the results of our early experiments on the feasibility and suitability of these types of interactions."
  },
  {
    "objectID": "pubs/sentiment-bias/index.html",
    "href": "pubs/sentiment-bias/index.html",
    "title": "Sentiment Bias in Predictive Text Recommendations Results in Biased Writing",
    "section": "",
    "text": "PDF In GI’18"
  },
  {
    "objectID": "pubs/sentiment-bias/index.html#abstract",
    "href": "pubs/sentiment-bias/index.html#abstract",
    "title": "Sentiment Bias in Predictive Text Recommendations Results in Biased Writing",
    "section": "Abstract",
    "text": "Abstract\nPrior research has demonstrated that intelligent systems make biased decisions because they are trained on biased data. As people increasingly leverage intelligent systems to enhance their productivity and creativity, could system biases affect what people create? We demonstrate that in at least one domain (writing restaurant reviews), biased system behavior leads to biased human behavior: People presented with phrasal text entry shortcuts that were skewed positive wrote more positive reviews than they did when presented with negative-skewed shortcuts. This result contributes to the pertinent debate about the role of intelligent systems in our society."
  },
  {
    "objectID": "pubs/phrase-suggestion/index.html",
    "href": "pubs/phrase-suggestion/index.html",
    "title": "On Suggesting Phrases vs. Predicting Words for Mobile Text Composition",
    "section": "",
    "text": "PDF In UIST’16"
  },
  {
    "objectID": "pubs/phrase-suggestion/index.html#abstract",
    "href": "pubs/phrase-suggestion/index.html#abstract",
    "title": "On Suggesting Phrases vs. Predicting Words for Mobile Text Composition",
    "section": "Abstract",
    "text": "Abstract\nA system capable of suggesting multi-word phrases while someone is writing could supply ideas about content and phrasing and allow those ideas to be inserted efficiently. Meanwhile, statistical language modeling has provided various approaches to predicting phrases that users type. We introduce a simple extension to the familiar mobile keyboard suggestion interface that presents phrase suggestions that can be accepted by a repeated-tap gesture. In an extended composition task, we found that phrases were interpreted as suggestions that affected the content of what participants wrote more than conventional single-word suggestions, which were interpreted as predictions. We highlight a design challenge: how can a phrase suggestion system make valuable suggestions rather than just accurate predictions?"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Multidimensional Array Terminology\n\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2023\n\n\n\n\n\n\n\n\nAvoid Magical Thinking about AI\n\n\n\n\n\n\n\nai\n\n\nml\n\n\n\n\nEven if you’re not a computer scientist, you should learn enough about AI that you can steer its progress.\n\n\n\n\n\n\nJan 24, 2023\n\n\nKen Arnold\n\n\n\n\n\n\n\n\nStop trying to detect computer-generated writing.\n\n\n\n\n\n\n\nai\n\n\nml\n\n\nlm\n\n\n\n\nIt’s a risky distraction that just encourages an arms race.\n\n\n\n\n\n\nJan 17, 2023\n\n\nKen Arnold\n\n\n\n\n\n\n\n\nSolomon’s proverbs about AI\n\n\n\n\n\n\n\nai\n\n\nml\n\n\nlm\n\n\n\n\nA reflection without words on the difference between wisdom and its imitation.\n\n\n\n\n\n\nJan 16, 2023\n\n\nKen Arnold\n\n\n\n\n\n\n\n\nWithout Acknowledgment: Cultivating Gratitude in an ML age\n\n\n\n\n\n\n\nai\n\n\nml\n\n\nlm\n\n\nia\n\n\n\n\nCreativity support tools based on machine learning hide the human authors that contributed to the work. Does it have to be that way?\n\n\n\n\n\n\nJan 12, 2023\n\n\nKen Arnold\n\n\n\n\n\n\n\n\nLanguage Models for Species-Scale Collaboration\n\n\n\n\n\n\n\nai\n\n\nml\n\n\nlm\n\n\nia\n\n\n\n\nHow knowledge fusion will continue the trend of scaling humam collaboration\n\n\n\n\n\n\nJan 11, 2023\n\n\nKen Arnold\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "bio.html",
    "href": "bio.html",
    "title": "Bios",
    "section": "",
    "text": "Assistant professor of computer science and data science at Calvin University. Crafting tools to augment intelligence, teaching students to build and use tech wisely."
  },
  {
    "objectID": "bio.html#medium50-words",
    "href": "bio.html#medium50-words",
    "title": "Bios",
    "section": "Medium(50 words)",
    "text": "Medium(50 words)\nKen Arnold (B.S., Cornell; M.S., MIT; Ph.D., Harvard) is an assistant professor of computer science and data science at Calvin University. His research has shown how predictive text interfaces, like those in smartphone keyboards and email apps, can shape the content of what people communicate. His current research interests include human-AI interaction in communication, creativity, and education."
  },
  {
    "objectID": "bio.html#longer",
    "href": "bio.html#longer",
    "title": "Bios",
    "section": "Longer",
    "text": "Longer\nKen Arnold (B.S., Cornell; M.S., MIT; Ph.D., Harvard) is an assistant professor of computer science and data science at Calvin University. His research has shown how predictive text interfaces, like those in smartphone keyboards and email apps, can shape the content of what people communicate. He is currently working on intelligence augmentation to help writers craft words that are fully their own. His current research interests include human-AI interaction in communication, creativity, and education."
  }
]